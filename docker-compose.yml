version: '3.8'

services:
  # ===========================================
  # REVERSE PROXY & LOAD BALANCER
  # ===========================================
  nginx:
    image: nginx:alpine
    container_name: ftex-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - frontend
      - backend
    networks:
      - ftex-network
    restart: unless-stopped

  # ===========================================
  # FRONTEND SERVICE - React/Next.js
  # ===========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ftex-frontend
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost/api
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - ftex-network
    restart: unless-stopped

  # ===========================================
  # BACKEND API - FastAPI/Python
  # ===========================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ftex-backend
    environment:
      - PYTHONUNBUFFERED=1
      - DATABASE_URL=postgresql://ftex:ftex_secret@postgres:5432/ftex_db
      - REDIS_URL=redis://redis:6379/0
      - OPENSEARCH_URL=http://opensearch:9200
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=ftex_secret
      - SPARK_MASTER_URL=spark://spark-master:7077
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - redis
      - opensearch
      - neo4j
    volumes:
      - ./backend:/app
      - shared-data:/data
    networks:
      - ftex-network
    restart: unless-stopped

  # ===========================================
  # DATABASE - PostgreSQL
  # ===========================================
  postgres:
    image: postgres:15-alpine
    container_name: ftex-postgres
    environment:
      - POSTGRES_USER=ftex
      - POSTGRES_PASSWORD=ftex_secret
      - POSTGRES_DB=ftex_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - ftex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ftex -d ftex_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================
  # CACHE - Redis
  # ===========================================
  redis:
    image: redis:7-alpine
    container_name: ftex-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - ftex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================
  # SEARCH ENGINE - OpenSearch
  # ===========================================
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: ftex-opensearch
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - ftex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.11.0
    container_name: ftex-opensearch-dashboards
    environment:
      - OPENSEARCH_HOSTS=["http://opensearch:9200"]
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true
    ports:
      - "5601:5601"
    depends_on:
      - opensearch
    networks:
      - ftex-network
    restart: unless-stopped

  # ===========================================
  # GRAPH DATABASE - Neo4j for Entity Resolution
  # ===========================================
  neo4j:
    image: neo4j:5.15-community
    container_name: ftex-neo4j
    environment:
      - NEO4J_AUTH=neo4j/ftex_secret
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_memory_heap_initial__size=512M
      - NEO4J_dbms_memory_heap_max__size=1G
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    networks:
      - ftex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ===========================================
  # SPARK CLUSTER - Data Processing
  # ===========================================
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ftex-spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master
    volumes:
      - ./spark/jobs:/opt/spark/jobs
      - shared-data:/data
    networks:
      - ftex-network
    restart: unless-stopped

  spark-worker-1:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ftex-spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./spark/jobs:/opt/spark/jobs
      - shared-data:/data
    networks:
      - ftex-network
    restart: unless-stopped

  spark-worker-2:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ftex-spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./spark/jobs:/opt/spark/jobs
      - shared-data:/data
    networks:
      - ftex-network
    restart: unless-stopped

  # ===========================================
  # MESSAGE QUEUE - Kafka (for real-time streaming)
  # ===========================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: ftex-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - ftex-network
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ftex-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - ftex-network
    restart: unless-stopped

# ===========================================
# NETWORKS
# ===========================================
networks:
  ftex-network:
    driver: bridge

# ===========================================
# VOLUMES
# ===========================================
volumes:
  postgres-data:
  redis-data:
  opensearch-data:
  neo4j-data:
  neo4j-logs:
  shared-data:

